{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab708185-f1f6-41c0-9433-77f7af8cacd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66836d7c-c88a-4465-97a9-3dd119234173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "executable_path = {'executable_path': '/Users/Justin1/.wdm/drivers/chromedriver/mac64/98.0.4758.102/chromedriver'} \n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d195a7b2-42f6-4142-822c-44ff1047a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://transcripts.foreverdreaming.org/viewforum.php?f=574'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596b7b9c-8579-4bad-b047-f401b2a16f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "bsoup = soup(html, 'html.parser')\n",
    "transcript = {}\n",
    "characters = []\n",
    "script_df = pd.DataFrame(columns = ['character','line','season','episode','line_ID'])\n",
    "\n",
    "for i in range(1,9):\n",
    "    if i == 1:\n",
    "        seas_ep = bsoup.find_all('h3')\n",
    "        for j in range(1,(len(seas_ep))):\n",
    "            link_text = seas_ep[j].a.get_text()\n",
    "            if link_text.find('99') != -1:\n",
    "                print(\"Found '99'...Moving to next line.\")\n",
    "                continue\n",
    "            else:\n",
    "                browser.links.find_by_partial_text(link_text).click()\n",
    "                html = browser.html\n",
    "                bsoup = soup(html, 'html.parser')\n",
    "                scripts = bsoup.find('div', class_='postbody')\n",
    "                all_lines = scripts.find_all('p', recursive=False)\n",
    "                print(f'gathering scripts from \"{link_text}\"')\n",
    "                for line in all_lines:\n",
    "                    substring_list = ['Deleted','Season','Webisode']\n",
    "                    try:\n",
    "                        name = line.find('strong').get_text()\n",
    "                        if any(substring in name for substring in substring_list) == True:\n",
    "                            continue\n",
    "                        else:\n",
    "                            line = line.get_text().replace(f'{name}: ','')\n",
    "                            if name not in characters:\n",
    "                                characters.append(name)\n",
    "                                seas=(int(link_text[:2]))*100\n",
    "                                ep=int(link_text[3:5])\n",
    "                                lineID= int((seas)+(ep))\n",
    "                                temp_df = pd.DataFrame([[name,line,seas,ep,lineID]],\n",
    "                                                       columns =['character','line','season','episode','line_ID'] )\n",
    "                                script_df = pd.concat([script_df,temp_df], ignore_index=True, axis=0)\n",
    "                            else:\n",
    "                                seas=(int(link_text[:2]))*100\n",
    "                                ep=int(link_text[3:5])\n",
    "                                lineID= int((seas)+(ep))\n",
    "                                temp_df = pd.DataFrame([[name,line,seas,ep,lineID]],\n",
    "                                                       columns =['character','line','season','episode','line_ID'] )\n",
    "                                script_df = pd.concat([script_df,temp_df], ignore_index=True, axis=0)\n",
    "                    except:\n",
    "                        print('SKIPPPPPPPPPPPPPED')\n",
    "                        pass\n",
    "                browser.back()\n",
    "\n",
    "    else:\n",
    "        page_numbers = browser.links.find_by_text(i)\n",
    "        page_numbers.click()\n",
    "        html = browser.html\n",
    "        bsoup = soup(html, 'html.parser')\n",
    "    #   time.sleep(3)\n",
    "        seas_ep = bsoup.find_all('h3')\n",
    "        for j in range(1,(len(seas_ep))):\n",
    "            link_text = seas_ep[j].a.get_text()\n",
    "            if link_text.find('99') != -1:\n",
    "                print(\"Found '99'...Moving to next line.\")\n",
    "                continue\n",
    "            else:\n",
    "                browser.links.find_by_partial_text(link_text).click()\n",
    "                html = browser.html\n",
    "                bsoup = soup(html, 'html.parser')\n",
    "                scripts = bsoup.find('div', class_='postbody')\n",
    "                all_lines = scripts.find_all('p', recursive=False)\n",
    "                print(f'gathering scripts from \"{link_text}\"')\n",
    "                for line in all_lines:\n",
    "                    substring_list = ['Deleted','Season','Webisode']\n",
    "                    try:\n",
    "                        name = line.find('strong').get_text()\n",
    "                        if any(substring in name for substring in substring_list) == True:\n",
    "                            continue\n",
    "                        else:\n",
    "                            line = line.get_text().replace(f'{name}: ','')\n",
    "                            if name not in characters:\n",
    "                                characters.append(name)\n",
    "                                seas=(int(link_text[:2]))*100\n",
    "                                ep=int(link_text[3:5])\n",
    "                                lineID= int((seas)+(ep))\n",
    "                                temp_df = pd.DataFrame([[name,line,seas,ep,lineID]],\n",
    "                                                       columns =['character','line','season','episode','line_ID'] )\n",
    "                                script_df = pd.concat([script_df,temp_df], ignore_index=True, axis=0)\n",
    "                            else:\n",
    "                                seas=int(int(link_text[:2]))*100\n",
    "                                ep=int(link_text[3:5])\n",
    "                                lineID= int((seas)+(ep))\n",
    "                                temp_df = pd.DataFrame([[name,line,seas,ep,lineID]],\n",
    "                                                       columns =['character','line','season','episode','line_ID'] )\n",
    "                                script_df = pd.concat([script_df,temp_df], ignore_index=True, axis=0)\n",
    "                    except:\n",
    "                        print('SKIPPPPPPPPPPPPPED')\n",
    "                        pass\n",
    "                browser.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d91cf152-70f1-47a8-a3a3-517a53e321bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>line</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>line_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [character, line, season, episode, line_ID]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df=script_df\n",
    "new_df[new_df['episode'] == 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfacf8cc-3619-49d3-b9e2-fd8b61eb9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('./Data/Scripts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d24b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5335827f-2c20-4d70-a39e-3ecbee449048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
